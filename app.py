import streamlit as st
import os
from groq import Groq
from dotenv import load_dotenv

# --- Configuraci√≥n de la P√°gina ---
st.set_page_config(
    page_title="ILLARI - Asistente Virtual",
    page_icon="üëÅÔ∏è",
    layout="centered"
)

# --- Carga de la Clave API de Forma Segura ---
load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY")

if not API_KEY:
    st.error("Falta GROQ_API_KEY en .env o en st.secrets.")
    st.stop()

client = Groq(api_key=API_KEY)


# --- (CAMBIO 1) Almacenar el conocimiento del proyecto en una variable ---
# Aqu√≠ guardamos toda la informaci√≥n que queremos que el chatbot sepa.
ILLARI_CONTEXT = """
El proyecto ILLARI es una iniciativa de innovaci√≥n en tecnolog√≠a m√©dica y salud p√∫blica que nace en el Per√∫ con el objetivo de resolver un problema cr√≠tico y desatendido: la falta de acceso al diagn√≥stico oftalmol√≥gico especializado en zonas rurales y remotas del pa√≠s.

Su n√∫cleo es el desarrollo de ILLARI, un top√≥grafo corneal port√°til de bajo costo, integrado con una plataforma de telemedicina.

### Componentes Clave:

#### 1. El Problema: La Brecha de Diagn√≥stico en la Salud Ocular Peruana
- **Enfermedades corneales:** Afecciones como el queratocono deforman la c√≥rnea y distorsionan la visi√≥n. Si no se detectan a tiempo, pueden llevar a la necesidad de un trasplante de c√≥rnea.
- **Barrera Geogr√°fica y Econ√≥mica en Per√∫:** Cerca del 65% de las personas con ceguera viven en √°reas rurales con escasez de oftalm√≥logos y equipos. Los top√≥grafos corneales est√°ndar son costosos y se encuentran solo en grandes ciudades, obligando a los pacientes a realizar viajes largos y costosos. El proyecto ataca la ceguera evitable por falta de diagn√≥stico.

#### 2. La Soluci√≥n Tecnol√≥gica: El Dispositivo ILLARI
- **¬øQu√© es un Top√≥grafo Corneal?:** Un instrumento que mapea la superficie de la c√≥rnea en 3D para detectar deformaciones.
- **Diferencias de ILLARI:**
  - **Portabilidad:** Ligero, robusto y f√°cil de transportar para llevarlo a campa√±as de salud en comunidades remotas.
  - **Bajo Costo:** Dise√±o y producci√≥n que reducen dr√°sticamente el precio en comparaci√≥n con equipos importados.
  - **Facilidad de Uso:** Interfaz dise√±ada para que personal de salud no especializado (t√©cnicos, enfermeros) pueda capturar las im√°genes.

#### 3. El Modelo de Servicio: La Integraci√≥n con Telemedicina
- **Diagn√≥stico a Distancia:** El dispositivo captura las im√°genes en la posta rural y las env√≠a a una plataforma en la nube.
- **Conexi√≥n con Especialistas:** Un oftalm√≥logo en cualquier ciudad accede a las im√°genes, emite un diagn√≥stico y lo env√≠a de vuelta.
- **Impacto:** Este sistema de tele-oftalmolog√≠a rompe la barrera geogr√°fica, democratiza el acceso a la atenci√≥n especializada, optimiza el tiempo de los oftalm√≥logos y reduce costos y tiempos de espera para el paciente.
"""

# --- (CAMBIO 2) Crear un prompt de sistema mucho m√°s potente ---
# Le damos instrucciones claras y le entregamos todo el contexto que debe usar.
SYSTEM_PROMPT = f"""
Eres un asistente virtual experto y representante del proyecto ILLARI. Tu misi√≥n es responder a las preguntas de los usuarios de manera amable y precisa, bas√°ndote exclusivamente en el siguiente contexto que se te proporciona. No inventes informaci√≥n que no est√© en este texto.

---
CONTEXTO DEL PROYECTO ILLARI:
{ILLARI_CONTEXT}
---

Si el usuario te pregunta algo que no est√° relacionado con el proyecto ILLARI, responde amablemente que tu funci√≥n es solo proporcionar informaci√≥n sobre ILLARI.
"""

# --- T√≠tulo y Logo ---
st.image('ojo.jpg', width=100)
st.title("Asistente Virtual del Proyecto ILLARI")

# --- Explicaci√≥n del Proyecto en un Expansor (para el usuario humano) ---
with st.expander("Conoce m√°s sobre el Proyecto ILLARI"):
    # Usamos la misma variable para no repetir texto
    st.markdown(ILLARI_CONTEXT, unsafe_allow_html=True)

# --- Configuraci√≥n del Chatbot ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- Renderizado del Historial de Chat ---
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- L√≥gica del Chat ---
user_input = st.chat_input("Haz una pregunta sobre el proyecto ILLARI...")

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Construir mensajes para el modelo
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    
    # A√±adimos solo el historial reciente para no sobrecargar el prompt
    for msg in st.session_state.chat_history:
        messages.append({"role": msg["role"], "content": msg["content"]})

    # Llamar a la API
    try:
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=messages,
            temperature=0.7,
        )
        respuesta_texto = response.choices[0].message.content
    except Exception as e:
        respuesta_texto = f"Lo siento, ocurri√≥ un error al llamar a la API: `{e}`"

    st.session_state.chat_history.append({"role": "assistant", "content": respuesta_texto})
    with st.chat_message("assistant"):
        st.markdown(respuesta_texto)

# PAra correr localmente usar: streamlit run app.py